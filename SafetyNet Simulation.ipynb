{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import random \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "global_seed = 0\n",
    "random.seed(global_seed)\n",
    "npr.seed(global_seed)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Please see KnapsackNetsModified.py is KnapsackNets.py with a few small changes to make it run w/o errors.\n",
    "- Added unsqueezes to make dimensions fit\n",
    "- commented out a few lines (normalize_jk) that were failing + output wasn't used for anything downstream\n",
    "\n",
    "In initial runs -- using v37, not v46. Q around what the difference is and which one to use?\n",
    "\"\"\"\n",
    "\n",
    "from KnapsackNetsModified import SafetyNet\n",
    "#from KnapsackNets import SafetyNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Simulation Parameters\n",
    "\n",
    "From JK thesis!\n",
    "- https://www.cmu.edu/tepper/programs/phd/program/assets/dissertations/2017-joint-phd-program-algorithms-combinatorics-and-optimization-karp-dissertation.pdf\n",
    "\n",
    "- Demand for each cluster is modeled as a Poisson process whose rate parameter is drawn from a Normal distribution\n",
    "with mean 10 and standard deviation 5. \n",
    "- Each day of the simulation allows the Poisson processes generating demand to run for either 40 or 400 time units (depending on simulation condition). \n",
    "- Inventory distributions for each category are modeled as Poisson distributions with rate parameters drawn from a Uniform distribution from 1 to 20. \n",
    "- The price of items in each category is drawn from a Normal distribution with mean 800 and standard deviation 400. \n",
    "- Each order is assigned a cancel probability based on a logistic function of the form 1 − 1/1+ea+b·I , where I is the item’s stated inventory level and a and b are parameters of the item’s category. a and b are drawn for each category from Normal distribution with mean .5 and −.2 and standard deviations .1 and either .05 or .15 (depending on simulation condition), respectively. \n",
    "- The inventory distribution parameters, cancel parameters, demand rates, and prices are all truncated at 0 to prevent negative values.\n",
    "- We vary data truncation by setting our benchmark Retail-1-threshold policies to single thresholds\n",
    "of either 8 or 14, allowing approximately 1/3 and 2/3 of total demand to get truncated,\n",
    "respectively. \n",
    "- Volume of demand is varied by allowing either 40 or 400 time units\n",
    "for the demand generating Poisson process during each period of the simulation.\n",
    "- We control cancel variability by running simulations where the standard deviation\n",
    "of cancel parameter b is .05 as well as .15. \n",
    "- We use the corresponding Retail-1-threshold policy as the starting threshold for the Onera policies and then\n",
    "let the Onera policies train on the data it collects and determine its own thresholds\n",
    "for the remaining days. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimulationParams import SafetyNetSimulation \n",
    "\n",
    "\"\"\"\n",
    "Please see SimulationParams.py for this implementation...!\n",
    "\"\"\"\n",
    "safety_net_simulation = SafetyNetSimulation(\n",
    "                 is_high_demand=False, \n",
    "                 is_high_truncation=False, \n",
    "                 is_high_variable_cancel_rate=False)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize SafetyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_safety_net(safety_net_simulation):\n",
    "    starting_retail_policy_1_threshold = torch.zeros(safety_net_simulation.nCategories, \n",
    "                                       safety_net_simulation.nThresholds)\n",
    "    starting_retail_policy_1_threshold[:,safety_net_simulation.retail_1_threshold_policy] = 1\n",
    "\n",
    "    safety_net = SafetyNet(\n",
    "        nKnapsackCategories=safety_net_simulation.nCategories, \n",
    "        nThresholds=safety_net_simulation.nThresholds, \n",
    "        starting_thresholds=starting_retail_policy_1_threshold, \n",
    "        # all possible thresholds? Or is this retail policy 1?\n",
    "        parametric_knapsack=False # First Pass, turn off LP layer\n",
    "        # Q: What should we be doing with the remaining variables here?\n",
    "    )\n",
    "    return safety_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Opt/Est learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_opt_est_params(safety_net):\n",
    "    # JK provided learning rates\n",
    "    safety_net_optimizer_est = torch.optim.SGD([\n",
    "    {'params':[safety_net.prices_est]}, #what will happen here since there is no learning rate? will it always stay the same?\n",
    "    {'params':[safety_net.inventory_lam_est], 'lr': 1e-0},\n",
    "    {'params':[safety_net.demand_distribution_est], 'lr': 1e-2},\n",
    "    {'params':[safety_net.cancel_coef_est], 'lr': 5e-3},\n",
    "    {'params':[safety_net.cancel_intercept_est], 'lr': 1e-1}\n",
    "        ], lr=1e-7)\n",
    "\n",
    "    safety_net_optimizer_opt = torch.optim.SGD([\n",
    "    {'params':[safety_net.inventory_lam_opt], 'lr': 2e-5},\n",
    "    {'params':[safety_net.demand_distribution_opt], 'lr': 1e-5},\n",
    "    {'params':[safety_net.cancel_coef_opt], 'lr': 2e-7},\n",
    "    {'params':[safety_net.cancel_intercept_opt], 'lr': 2e-6}\n",
    "        ], lr=1e-8)\n",
    "\n",
    "    safety_net_optimizer_RHS =torch.optim.SGD([\n",
    "    {'params':[safety_net.cancel_rate_param, safety_net.accept_rate_param], 'lr': 1e-6}\n",
    "        ], lr=1e-8)\n",
    "    \n",
    "    return safety_net_optimizer_est, safety_net_optimizer_opt, safety_net_optimizer_RHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Period: 0\n",
      "Batch:  0\n",
      "New Revenue Loss tensor(-5.2655) New Cancel Constraint Loss tensor(24.1175) New Accept Constraint Loss tensor(-7.3546)\n",
      "Obs Cancel Constraint Loss tensor(24.1175) Obs Accept Constraint Loss tensor(-7.3546) LP Infeasible 0\n",
      "Batch:  5\n",
      "New Revenue Loss tensor(-4.9721) New Cancel Constraint Loss tensor(27.0034) New Accept Constraint Loss tensor(-6.4566)\n",
      "Obs Cancel Constraint Loss tensor(27.0034) Obs Accept Constraint Loss tensor(-6.4566) LP Infeasible 0\n",
      "Batch:  10\n",
      "New Revenue Loss tensor(-5.0297) New Cancel Constraint Loss tensor(23.3906) New Accept Constraint Loss tensor(-6.8585)\n",
      "Obs Cancel Constraint Loss tensor(23.3906) Obs Accept Constraint Loss tensor(-6.8585) LP Infeasible 0\n",
      "Batch:  15\n",
      "New Revenue Loss tensor(-5.0831) New Cancel Constraint Loss tensor(22.9478) New Accept Constraint Loss tensor(-7.2646)\n",
      "Obs Cancel Constraint Loss tensor(22.9478) Obs Accept Constraint Loss tensor(-7.2646) LP Infeasible 0\n",
      "Batch:  20\n",
      "New Revenue Loss tensor(-5.9467) New Cancel Constraint Loss tensor(25.9461) New Accept Constraint Loss tensor(-7.6363)\n",
      "Obs Cancel Constraint Loss tensor(25.9461) Obs Accept Constraint Loss tensor(-7.6363) LP Infeasible 0\n",
      "Batch:  25\n",
      "New Revenue Loss tensor(-4.8577) New Cancel Constraint Loss tensor(23.1745) New Accept Constraint Loss tensor(-6.9751)\n",
      "Obs Cancel Constraint Loss tensor(23.1745) Obs Accept Constraint Loss tensor(-6.9751) LP Infeasible 0\n",
      "Batch:  30\n",
      "New Revenue Loss tensor(-5.3139) New Cancel Constraint Loss tensor(24.6808) New Accept Constraint Loss tensor(-7.1028)\n",
      "Obs Cancel Constraint Loss tensor(24.6808) Obs Accept Constraint Loss tensor(-7.1028) LP Infeasible 0\n",
      "Order Period: 1\n",
      "iter: 0, pri_resid: 7.51652e+01, dual_resid: 3.19496e+01, mu: 2.22388e+00\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type float without overflow: 10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7f8ab904d8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mcancel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_cancel_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mcollection_thresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_collection_thresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/safetynet/KnapsackNetsModified.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, category, inv_count, price, cancel, collection_thresholds)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minequalityVector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknapsack_cancels_RHS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknapsack_fills_RHS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPosValVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0mthresholds_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQPFunctionJK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknapsack_revenues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minequalityMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minequalityVector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds_raw_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresholds_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnKnapsackCategories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m#self.accept_rate=1.0*self.accept_rate_original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/qpth/qp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q_, p_, G_, h_, A_, b_)\u001b[0m\n\u001b[1;32m     92\u001b[0m             zhats, self.nus, self.lams, self.slacks = pdipm_b.forward(\n\u001b[1;32m     93\u001b[0m                 \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 self.eps, self.verbose, self.notImprovedLim, self.maxIter)\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQPSolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCVXPY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/qpth/solvers/pdipm/batch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(Q, p, G, h, A, b, Q_LU, S_LU, R, eps, verbose, notImprovedLim, maxIter, solver)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mI_neq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI_neq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI_neq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnNotImproved\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnotImprovedLim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINACC_ERR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type float without overflow: 10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000"
     ]
    }
   ],
   "source": [
    "num_periods = 7 # or epochs\n",
    "nBatches = 32\n",
    "\n",
    "safety_net = init_safety_net(safety_net_simulation)\n",
    "safety_net_optimizer_est, safety_net_optimizer_opt, safety_net_optimizer_RHS = init_opt_est_params(safety_net)\n",
    "\n",
    "for i in range(num_periods):\n",
    "    print(\"Order Period: \" + str(i))\n",
    "    # Generate orders for period\n",
    "    orders, inv_count, price, cancel_probs, collection_thresholds = safety_net_simulation.generate_data()\n",
    "    batch_size = int(orders.shape[0]/nBatches)\n",
    "    \n",
    "    if i == 0:\n",
    "        safety_net.parametric_knapsack = False\n",
    "    else:\n",
    "        safety_net.parametric_knapsack = True\n",
    "        \n",
    "    head = 0\n",
    "    tail = batch_size\n",
    "    n_orders = orders.shape[0]\n",
    "    batch_num = 0\n",
    "    while tail < orders.shape[0]:\n",
    "        \n",
    "        ## Grab the next batch of order and corresponding inv, price, cancel, thresh info\n",
    "        tail = np.min([n_orders-1, head+batch_size])\n",
    "        if (n_orders - 1 - tail) < batch_size:\n",
    "            tail = n_orders\n",
    "        batch_orders = orders[head:tail,:]\n",
    "        batch_inv_count = inv_count[head:tail,:]\n",
    "        batch_price = price[head:tail]\n",
    "        batch_cancel_probs = cancel_probs[head:tail]\n",
    "        batch_collection_thresholds = collection_thresholds[head:tail,:]\n",
    "        \n",
    "        head = tail\n",
    "\n",
    "        # Forward Pass\n",
    "        (new_revenue_loss, #renamed from new_objective_loss\n",
    "         new_cancel_constraint_loss, \n",
    "         new_accept_constraint_loss, \n",
    "         arrival_probability_batch_by_threshold, \n",
    "         log_arrival_prob, \n",
    "         log_cancel_prob, \n",
    "         log_category_prob, \n",
    "         estimated_batch_total_demand, \n",
    "         observed_cancel_constraint_loss, \n",
    "         observed_accept_constraint_loss, \n",
    "         lp_infeasible) = safety_net.forward(\n",
    "            category=Variable(torch.from_numpy(batch_orders.astype(np.float32))),\n",
    "            inv_count=torch.from_numpy(batch_inv_count.astype(np.float32)),\n",
    "            price=torch.from_numpy(batch_price.astype(np.float32)),\n",
    "            cancel=torch.from_numpy(batch_cancel_probs.astype(np.float32)),\n",
    "            collection_thresholds=torch.from_numpy(batch_collection_thresholds.astype(np.float32))\n",
    "        )\n",
    "        \n",
    "        # \"logging\"\n",
    "        if batch_num % 5 == 0:\n",
    "            print(\"Batch: \", batch_num)\n",
    "            print(\n",
    "             \"New Revenue Loss\", new_revenue_loss, #renamed from new_objective_loss\n",
    "             \"New Cancel Constraint Loss\", new_cancel_constraint_loss, \n",
    "             \"New Accept Constraint Loss\", new_accept_constraint_loss)\n",
    "            print( \n",
    "             \"Obs Cancel Constraint Loss\", observed_cancel_constraint_loss, \n",
    "             \"Obs Accept Constraint Loss\", observed_accept_constraint_loss, \n",
    "             \"LP Infeasible\", lp_infeasible)\n",
    "\n",
    "        # Backward Pass\n",
    "        \n",
    "        # zero grad\n",
    "        safety_net_optimizer_est.zero_grad()\n",
    "        safety_net_optimizer_opt.zero_grad()\n",
    "        safety_net_optimizer_RHS.zero_grad()\n",
    "\n",
    "        is_cancel_constraint_violated = new_cancel_constraint_loss < 0 # TODO: How to calculate is_cancel_constraint_violated?\n",
    "        is_other_constraints_violated = new_accept_constraint_loss > 0 # TODO: How to calculate is_other_constraints_violated?\n",
    "\n",
    "        # update parameters based on violation logic\n",
    "        # TODO: If both constraints are violated, do we run backward for both cancel and accept?\n",
    "        if is_cancel_constraint_violated: \n",
    "            new_cancel_constraint_loss.backward(retain_graph=True)\n",
    "            safety_net_optimizer_RHS.step()\n",
    "        if is_other_constraints_violated: \n",
    "            new_accept_constraint_loss.backward()\n",
    "            safety_net_optimizer_RHS.step()\n",
    "        if not is_cancel_constraint_violated and not is_other_constraints_violated:\n",
    "            #print(safety_net.inventory_lam_est)\n",
    "            #print(safety_net.demand_distribution_est)\n",
    "            #print(safety_net.cancel_coef_est)\n",
    "            #print(safety_net.cancel_intercept_est)\n",
    "\n",
    "            new_revenue_loss.backward()\n",
    "            if i == 0:\n",
    "                #IF first pass, then we only step for estimation parameters AND\n",
    "                #manually copy values of temp_optimizer_est into temp_optimizer_opt params\n",
    "                safety_net_optimizer_est.step()\n",
    "                # Manually copy values of est params into opt params\n",
    "                safety_net.inventory_lam_opt = safety_net.inventory_lam_est\n",
    "                safety_net.demand_distribution_opt = safety_net.demand_distribution_est\n",
    "                safety_net.cancel_coef_opt = safety_net.cancel_coef_est\n",
    "                safety_net.cancel_intercept_opt = safety_net.cancel_intercept_est\n",
    "            else:    \n",
    "                safety_net_optimizer_est.step()\n",
    "                safety_net_optimizer_opt.step()\n",
    "        \n",
    "        batch_num +=1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
